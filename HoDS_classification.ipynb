{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of some helper functions that are useful later\n",
    "\n",
    "# Helper function for training classifier. Gridsearch and K-fold cross validation also done.\n",
    "def train_classifier(classifier, param_grid, cv, data):\n",
    "    X_train, y_train = data\n",
    "    class_gridsearch = GridSearchCV(estimator = classifier, param_grid = param_grid, cv = cv)\n",
    "    class_gridsearch.fit(X_train, y_train) \n",
    "    return class_gridsearch.best_estimator_\n",
    "\n",
    "# Helper function for evaluating trained classifier.\n",
    "def evaluate_classifier(classifier, data):\n",
    "    X_train, X_val, y_train, y_val = data\n",
    "    y_pred_val = classifier.predict(X_val)\n",
    "    y_pred_train = classifier.predict(X_train)  \n",
    "    print(classification_report(y_val, y_pred_val))\n",
    "    print('Accuracy score (validation data): ', accuracy_score(y_val, y_pred_val))\n",
    "    print('Accuracy score (train data): ', accuracy_score(y_train, y_pred_train))\n",
    "    \n",
    "# Outputs test data predictions to csv for upload to Kaggle.    \n",
    "def testdata_submission(classifier, test_data):\n",
    "    submission = pd.DataFrame(index = test_data.index)\n",
    "    submission['type'] = classifier.predict(test_data)\n",
    "    submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading and pre-processing\n",
    "train_df = pd.read_csv('train.csv', index_col = 'id')\n",
    "test_df = pd.read_csv('test.csv', index_col = 'id')\n",
    "\n",
    "# Convert categorical color feature to one hot encoding\n",
    "train_df = pd.get_dummies(train_df, columns = ['color'])\n",
    "test_df = pd.get_dummies(test_df, columns = ['color'])\n",
    "\n",
    "# Split training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_df.drop(['type'], axis = 1), train_df['type'], test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {}\n",
    "\n",
    "# Logistic regression\n",
    "param_grid = {'C': [1, 10, 100, 1000, 10000, 100000, 1000000], 'penalty': ['l1', 'l2']}\n",
    "classifier = LogisticRegression()\n",
    "clfs['logreg'] = train_classifier(classifier, param_grid, 5, (X_train, y_train))\n",
    "\n",
    "evaluate_classifier(clfs['logreg'], (X_train, X_val, y_train, y_val))\n",
    "testdata_submission(clfs['logreg'], test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree\n",
    "param_grid = {}\n",
    "classifier = DecisionTreeClassifier()\n",
    "clfs['dt'] = train_classifier(classifier, param_grid, 5, (X_train, y_train))\n",
    "\n",
    "evaluate_classifier(clfs['dt'], (X_train, X_val, y_train, y_val))\n",
    "testdata_submission(clfs['dt'], test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "param_grid = {'n_estimators': [1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 100]}\n",
    "classifier = RandomForestClassifier()\n",
    "clfs['rf'] = train_classifier(classifier, param_grid, 5, (X_train, y_train))\n",
    "\n",
    "evaluate_classifier(clfs['rf'], (X_train, X_val, y_train, y_val))\n",
    "testdata_submission(clfs['rf'], test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Discriminant Analysis\n",
    "param_grid = {}\n",
    "classifier = LinearDiscriminantAnalysis()\n",
    "clfs['lda'] = train_classifier(classifier, param_grid, 5, (X_train, y_train))\n",
    "\n",
    "evaluate_classifier(clfs['lda'], (X_train, X_val, y_train, y_val))\n",
    "testdata_submission(clfs['lda'], test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging\n",
    "param_grid = {}\n",
    "classifier = BaggingClassifier()\n",
    "clfs['bagging'] = train_classifier(classifier, param_grid, 5, (X_train, y_train))\n",
    "\n",
    "evaluate_classifier(clfs['bagging'], (X_train, X_val, y_train, y_val))\n",
    "testdata_submission(clfs['bagging'], test_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
